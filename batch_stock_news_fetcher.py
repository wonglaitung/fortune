#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ‰¹é‡è·å–è‡ªé€‰è‚¡æ–°é—»è„šæœ¬
ä½œè€…ï¼šAI åŠ©æ‰‹
æ—¥æœŸï¼š2025-10-25
"""

import akshare as ak
import yfinance as yf
from datetime import datetime, time as dt_time
import json
import os
import csv
import time
import argparse
import schedule
from llm_services.qwen_engine import chat_with_llm

# å¯¼å…¥hk_smart_money_tracker.pyä¸­çš„WATCHLIST
import sys
sys.path.append('/data/fortune')
from hk_smart_money_tracker import WATCHLIST

def filter_news_with_llm(news_list, stock_name, stock_code, max_news=3):
    """
    ä½¿ç”¨å¤§æ¨¡å‹è¿‡æ»¤æ–°é—»ï¼Œè¯„ä¼°æ–°é—»ä¸è‚¡ç¥¨çš„ç›¸å…³æ€§ï¼Œå¹¶æŒ‰æ—¶é—´æ’åº
    """
    if not news_list:
        return []
    
    # å‡†å¤‡æ–°é—»æ•°æ®ç”¨äºå‘é€ç»™å¤§æ¨¡å‹
    news_texts = []
    for i, news in enumerate(news_list):
        news_text = f"{i+1}. æ ‡é¢˜: {news['title']}\n   å†…å®¹: {news['summary']}\n   å‘å¸ƒæ—¶é—´: {news['publishedAt']}\n"
        news_texts.append(news_text)
    
    news_data = "\n".join(news_texts)
    
    # æ„å»ºå¤§æ¨¡å‹æŸ¥è¯¢
    prompt = f"""
è¯·åˆ†æä»¥ä¸‹æ–°é—»ä¸è‚¡ç¥¨ \"{stock_name}\"ï¼ˆä»£ç ï¼š{stock_code}ï¼‰çš„ç›¸å…³æ€§ï¼Œå¹¶ç»¼åˆè€ƒè™‘ç›¸å…³æ€§å’Œæ—¶æ•ˆæ€§ï¼ˆå‘å¸ƒæ—¶é—´è¶Šè¿‘è¶Šé‡è¦ï¼‰ï¼ŒæŒ‰ç»¼åˆè¯„åˆ†ä»é«˜åˆ°ä½æ’åºï¼Œè¿”å›å‰{max_news}æ¡æ–°é—»çš„åºå·åˆ—è¡¨ã€‚

è‚¡ç¥¨ä¿¡æ¯ï¼š
- è‚¡ç¥¨åç§°ï¼š{stock_name}
- è‚¡ç¥¨ä»£ç ï¼š{stock_code}

æ–°é—»åˆ—è¡¨ï¼š
{news_data}

è¯·æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ç»“æœï¼š
{{
    \"relevant_news_indices\": [1, 3, 5, 2, 4]
}}

åªè¿”å›JSONæ ¼å¼ç»“æœï¼Œä¸è¦æ·»åŠ å…¶ä»–è§£é‡Šã€‚
"""
    
    try:
        # è°ƒç”¨å¤§æ¨¡å‹
        response = chat_with_llm(prompt)
        
        # è§£æå¤§æ¨¡å‹è¿”å›çš„JSON
        start_idx = response.find('{')
        end_idx = response.rfind('}') + 1
        if start_idx != -1 and end_idx != 0:
            json_str = response[start_idx:end_idx]
            result = json.loads(json_str)
            relevant_indices = result.get("relevant_news_indices", [])
            
            # æ ¹æ®å¤§æ¨¡å‹è¿”å›çš„åºå·è·å–ç›¸å…³æ–°é—»
            filtered_news = []
            for idx in relevant_indices[:max_news]:
                if 1 <= idx <= len(news_list):
                    filtered_news.append(news_list[idx-1])
            
            # æŒ‰æ—¶é—´ç”±è¿‘åˆ°è¿œæ’åº
            filtered_news.sort(key=lambda x: x['publishedAt'], reverse=True)
            
            return filtered_news
        else:
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„JSONï¼Œè¿”å›åŸå§‹æ•°æ®å¹¶æŒ‰æ—¶é—´æ’åº
            sorted_news = sorted(news_list[:max_news], key=lambda x: x['publishedAt'], reverse=True)
            return sorted_news
    except Exception as e:
        print(f"âš ï¸ å¤§æ¨¡å‹è¿‡æ»¤å¤±è´¥: {e}")
        # å¦‚æœå¤§æ¨¡å‹è°ƒç”¨å¤±è´¥ï¼Œè¿”å›åŸå§‹æ•°æ®å¹¶æŒ‰æ—¶é—´æ’åº
        sorted_news = sorted(news_list[:max_news], key=lambda x: x['publishedAt'], reverse=True)
        return sorted_news

def get_stock_news(symbol, stock_name="", size=3):
    """
    é€šè¿‡AKShareè·å–ä¸ªè‚¡æ–°é—»ï¼Œå¹¶ä½¿ç”¨å¤§æ¨¡å‹è¿›è¡Œç›¸å…³æ€§è¿‡æ»¤
    :param symbol: è‚¡ç¥¨ä»£ç  (ä¾‹å¦‚: "1810" for å°ç±³é›†å›¢)
    :param stock_name: è‚¡ç¥¨åç§° (ä¾‹å¦‚: "å°ç±³é›†å›¢")
    :param size: è·å–æ–°é—»æ¡æ•°
    :return: æ–°é—»åˆ—è¡¨
    """
    try:
        # ä½¿ç”¨AKShareè·å–ä¸ªè‚¡æ–°é—»
        df = ak.stock_news_em(symbol=symbol)
        articles = []
        
        # å¤„ç†æ–°é—»æ•°æ®
        for _, item in df.iterrows():
            # æ ¼å¼åŒ–å‘å¸ƒæ—¶é—´
            pub_time = item.get("å‘å¸ƒæ—¶é—´", "")
            if pub_time:
                # å°†æ—¶é—´å­—ç¬¦ä¸²è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
                try:
                    pub_time = datetime.strptime(pub_time, "%Y-%m-%d %H:%M:%S").strftime("%Y-%m-%d %H:%M:%S")
                except:
                    pass
            
            title = item.get("æ–°é—»æ ‡é¢˜", "").strip()
            summary = item.get("æ–°é—»å†…å®¹", "").strip()
            
            articles.append({
                "title": title[:80] + ("..." if len(title) > 80 else ""),
                "summary": summary[:120] + ("..." if len(summary) > 120 else ""),
                "url": item.get("æ–°é—»é“¾æ¥", ""),
                "publishedAt": pub_time
            })
        
        # å¦‚æœæ²¡æœ‰æŒ‡å®šè‚¡ç¥¨åç§°ï¼Œç›´æ¥è¿”å›åŸå§‹æ•°æ®
        if not stock_name:
            return articles[:size]
        
        # ä½¿ç”¨å¤§æ¨¡å‹è¿‡æ»¤ç›¸å…³æ–°é—»
        filtered_articles = filter_news_with_llm(articles, stock_name, symbol, size)
        return filtered_articles
    except Exception as e:
        print(f"âš ï¸ è·å–ä¸ªè‚¡æ–°é—»å¤±è´¥: {e}")
        return []

def get_stock_info(symbol):
    """è·å–è‚¡ä»·ä¸åŸºæœ¬é¢æ•°æ®"""
    try:
        ticker = yf.Ticker(symbol)
        info = ticker.info
        return {
            "name": info.get("longName", "N/A"),
            "price": info.get("currentPrice", "N/A"),
            "currency": info.get("currency", "HKD"),
            "market_cap": info.get("marketCap", "N/A"),
            "pe_ratio": info.get("trailingPE", "N/A"),
            "change": info.get("regularMarketChangePercent", "N/A")
        }
    except Exception as e:
        print(f"âš ï¸ è·å–è‚¡ä»·å¤±è´¥: {e}")
        return {}

def fetch_all_stock_news():
    """è·å–watch listä¸­æ‰€æœ‰è‚¡ç¥¨çš„æ–°é—»"""
    print("=" * 60)
    print("ğŸ“ˆ æ‰¹é‡è·å–è‡ªé€‰è‚¡æ–°é—»")
    print(f"ğŸ“… ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)
    
    # è·å–å½“å‰æŸ¥è¯¢æ—¶é—´
    query_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    
    all_news_data = []
    
    # åˆ é™¤è¶…æ—¶é™åˆ¶ï¼Œå¤„ç†æ‰€æœ‰è‚¡ç¥¨
    stock_count = 0
    
    for code, name in WATCHLIST.items():
        print(f"\nğŸ” æ­£åœ¨è·å– {name} ({code}) çš„æ–°é—»...")
        
        # æ ¹æ®è‚¡ç¥¨ä»£ç ç¡®å®šAKShareä½¿ç”¨çš„ä»£ç æ ¼å¼
        if "." in code:
            symbol_code = code.split(".")[0]
        else:
            symbol_code = code
        
        # è·å–æ–°é—»ï¼Œæ¯åªè‚¡ç¥¨è·å–3æ¡æ–°é—»
        articles = get_stock_news(symbol_code, name, size=3)
        
        if articles:
            print(f"  âœ… è·å–åˆ° {len(articles)} æ¡ç›¸å…³æ–°é—»")
            # æ·»åŠ åˆ°æ€»æ•°æ®ä¸­
            for article in articles:
                all_news_data.append({
                    "stock_name": name,
                    "stock_code": code,
                    "publishedAt": article.get("publishedAt", ""),
                    "title": article.get("title", ""),
                    "summary": article.get("summary", ""),
                    "query_time": query_time
                })
        else:
            print(f"  âš ï¸ æœªè·å–åˆ° {name} çš„æ–°é—»")
            
        stock_count += 1
        # çŸ­æš‚ä¼‘çœ ä»¥é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
        time.sleep(1)
    
    # ä¿å­˜æ‰€æœ‰æ–°é—»æ•°æ®åˆ°CSVæ–‡ä»¶
    if all_news_data:
        # ç¡®ä¿dataç›®å½•å­˜åœ¨
        data_dir = "data"
        if not os.path.exists(data_dir):
            os.makedirs(data_dir)
        
        # CSVæ–‡ä»¶è·¯å¾„
        csv_file = os.path.join(data_dir, "all_stock_news_records.csv")
        
        with open(csv_file, mode='w', newline='', encoding='utf-8') as file:
            writer = csv.writer(file)
            # å†™å…¥è¡¨å¤´
            writer.writerow(["è‚¡ç¥¨åç§°", "è‚¡ç¥¨ä»£ç ", "æ–°é—»æ—¶é—´", "æ–°é—»æ ‡é¢˜", "ç®€è¦å†…å®¹", "æŸ¥è¯¢æ—¶é—´"])
            # å†™å…¥æ•°æ®
            for news in all_news_data:
                writer.writerow([
                    news["stock_name"],
                    news["stock_code"],
                    news["publishedAt"],
                    news["title"],
                    news["summary"],
                    news["query_time"]
                ])
        
        print(f"\nâœ… æ‰€æœ‰æ–°é—»æ•°æ®å·²ä¿å­˜åˆ° {csv_file}")
        
        # æ˜¾ç¤ºæ±‡æ€»ä¿¡æ¯
        print("\nğŸ“‹ æ–°é—»æ±‡æ€»:")
        for news in all_news_data:
            print(f"  â€¢ {news['stock_name']} ({news['stock_code']}) | {news['title']}")
    else:
        print("\nâŒ æœªè·å–åˆ°ä»»ä½•æ–°é—»æ•°æ®")
        
    print(f"\nğŸ“Š æ€»å…±å¤„ç†äº† {stock_count} åªè‚¡ç¥¨")
    print("=" * 60)

def run_scheduler():
    """è®¾ç½®å®šæ—¶ä»»åŠ¡"""
    # è®¾ç½®é¦™æ¸¯æ—¶é—´ä¸Šåˆ9ç‚¹å’Œä¸‹åˆ1ç‚¹åŠè¿è¡Œ
    schedule.every().day.at("09:00").do(fetch_all_stock_news)
    schedule.every().day.at("13:30").do(fetch_all_stock_news)
    
    print("â° å®šæ—¶ä»»åŠ¡å·²è®¾ç½®å®Œæˆ")
    print("ğŸ“Œ æ¯å¤©é¦™æ¸¯æ—¶é—´ä¸Šåˆ9:00å’Œä¸‹åˆ13:30å°†è‡ªåŠ¨è¿è¡Œ")
    print("ğŸ“Œ æŒ‰ Ctrl+C åœæ­¢ç¨‹åº")
    
    while True:
        schedule.run_pending()
        time.sleep(60)  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡

if __name__ == "__main__":
    # åˆ›å»ºå‚æ•°è§£æå™¨
    parser = argparse.ArgumentParser(description='æ‰¹é‡è·å–è‡ªé€‰è‚¡æ–°é—»')
    parser.add_argument('--schedule', '-s', action='store_true', 
                        help='å¯ç”¨å®šæ—¶ä»»åŠ¡æ¨¡å¼ï¼ˆé»˜è®¤ï¼šå•æ¬¡è¿è¡Œï¼‰')
    
    # è§£æå‚æ•°
    args = parser.parse_args()
    
    if args.schedule:
        # å¯ç”¨å®šæ—¶ä»»åŠ¡æ¨¡å¼
        run_scheduler()
    else:
        # å•æ¬¡è¿è¡Œæ¨¡å¼
        fetch_all_stock_news()
