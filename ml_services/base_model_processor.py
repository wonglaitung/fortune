#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Base Model Processor - æä¾›æ¨¡å‹è®­ç»ƒå’Œåˆ†æçš„åŸºç¡€åŠŸèƒ½
"""

import os
import json
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc
import lightgbm as lgb
from ml_services.logger_config import get_logger

logger = get_logger('base_model_processor')


class BaseModelProcessor:
    """æ¨¡å‹å¤„ç†å™¨åŸºç±»"""

    def __init__(self):
        self.continuous_features = []
        self.category_features = []
        self.output_dir = 'output'

    def load_feature_config(self, config_path='config/feature_config.json'):
        """
        åŠ è½½ç‰¹å¾é…ç½®æ–‡ä»¶
        è¿”å›: bool æ˜¯å¦åŠ è½½æˆåŠŸ
        """
        if not os.path.exists(config_path):
            # å¦‚æœé…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®
            logger.warning(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
            print("â„¹ï¸  å°†ä½¿ç”¨é»˜è®¤é…ç½®ï¼ˆæ‰€æœ‰ç‰¹å¾è§†ä¸ºè¿ç»­ç‰¹å¾ï¼‰")
            return True

        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)

            self.continuous_features = config.get('continuous_features', [])
            self.category_features = config.get('category_features', [])

            logger.info(f"æˆåŠŸåŠ è½½ç‰¹å¾é…ç½®:")
            print(f"   - è¿ç»­ç‰¹å¾: {len(self.continuous_features)} ä¸ª")
            print(f"   - ç±»åˆ«ç‰¹å¾: {len(self.category_features)} ä¸ª")

            return True

        except Exception as e:
            logger.error(f"åŠ è½½ç‰¹å¾é…ç½®å¤±è´¥: {e}")
            return False

    def analyze_feature_importance(self, booster, feature_names):
        """
        åˆ†æç‰¹å¾é‡è¦æ€§
        è¿”å›: DataFrame åŒ…å«ç‰¹å¾é‡è¦æ€§ä¿¡æ¯
        """
        # è·å–ç‰¹å¾é‡è¦æ€§
        importance_gain = booster.feature_importance(importance_type='gain')
        importance_split = booster.feature_importance(importance_type='split')

        # åˆ›å»ºDataFrame
        feat_imp = pd.DataFrame({
            'Feature': feature_names,
            'Gain_Importance': importance_gain,
            'Split_Importance': importance_split
        })

        # å½’ä¸€åŒ–
        feat_imp['Gain_Importance'] = feat_imp['Gain_Importance'] / feat_imp['Gain_Importance'].sum()
        feat_imp['Split_Importance'] = feat_imp['Split_Importance'] / feat_imp['Split_Importance'].sum()

        # æŒ‰ Gain é‡è¦æ€§æ’åº
        feat_imp = feat_imp.sort_values('Gain_Importance', ascending=False).reset_index(drop=True)

        return feat_imp

    def calculate_ks_statistic(self, y_true, y_pred_proba):
        """
        è®¡ç®— KS ç»Ÿè®¡é‡
        è¿”å›: float KS å€¼
        """
        from scipy import stats

        # è®¡ç®—æ­£è´Ÿæ ·æœ¬çš„é¢„æµ‹æ¦‚ç‡
        pos = y_pred_proba[y_true == 1]
        neg = y_pred_proba[y_true == 0]

        # è®¡ç®— KS ç»Ÿè®¡é‡
        ks_statistic, p_value = stats.ks_2samp(pos, neg)

        return ks_statistic

    def plot_roc_curve(self, y_true, y_pred_proba, save_path='roc_curve.png'):
        """
        ç»˜åˆ¶ ROC æ›²çº¿
        """
        fpr, tpr, thresholds = roc_curve(y_true, y_pred_proba)
        roc_auc = auc(fpr, tpr)

        plt.figure(figsize=(8, 6))
        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')
        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title('Receiver Operating Characteristic (ROC) Curve')
        plt.legend(loc="lower right")
        plt.grid(True, alpha=0.3)

        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(save_path), exist_ok=True)
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        plt.close()

        logger.info(f"ROC æ›²çº¿å·²ä¿å­˜è‡³ {save_path}")

    def get_leaf_path_enhanced(self, booster, tree_index, leaf_index, feature_names, category_prefixes=None):
        """
        è§£æå¶å­èŠ‚ç‚¹çš„å†³ç­–è·¯å¾„ï¼ˆå¢å¼ºç‰ˆï¼‰
        è¿”å›: list å†³ç­–è§„åˆ™åˆ—è¡¨
        """
        try:
            tree_df = booster.trees_to_dataframe()
            
            # ç­›é€‰æŒ‡å®šæ ‘
            tree_data = tree_df[tree_df['tree_index'] == tree_index].copy()
            
            if tree_data.empty:
                return None
            
            # æ„å»ºå¶å­èŠ‚ç‚¹çš„node_indexï¼š{tree_index}-L{leaf_index}
            target_node_id = f"{tree_index}-L{leaf_index}"
            
            # æŸ¥æ‰¾å¶å­èŠ‚ç‚¹
            leaf_node = tree_data[tree_data['node_index'] == target_node_id]
            
            if leaf_node.empty:
                return None
            
            # å‘ä¸Šè¿½æº¯çˆ¶èŠ‚ç‚¹
            current_node_id = target_node_id
            path = []
            
            while True:
                node_info = tree_data[tree_data['node_index'] == current_node_id]
                if node_info.empty:
                    break
                    
                parent_id_str = node_info['parent_index'].values[0]
                
                # æ£€æŸ¥æ˜¯å¦åˆ°è¾¾æ ¹èŠ‚ç‚¹
                if pd.isna(parent_id_str) or parent_id_str == '':
                    break
                    
                # è·å–çˆ¶èŠ‚ç‚¹ä¿¡æ¯
                parent_info = tree_data[tree_data['node_index'] == parent_id_str]
                if parent_info.empty:
                    break
                
                # æ£€æŸ¥çˆ¶èŠ‚ç‚¹æ˜¯å¦æœ‰åˆ†è£‚ä¿¡æ¯
                if pd.notna(parent_info['split_feature'].values[0]):
                    feature_str = parent_info['split_feature'].values[0]
                    threshold = parent_info['threshold'].values[0]
                    left_child = parent_info['left_child'].values[0]
                    right_child = parent_info['right_child'].values[0]
                    
                    # è§£æç‰¹å¾ç´¢å¼•ï¼ˆä» "Column_X" æ ¼å¼ä¸­æå–ï¼‰
                    if isinstance(feature_str, str) and feature_str.startswith('Column_'):
                        try:
                            feature_idx = int(feature_str.split('_')[1])
                        except (ValueError, IndexError):
                            feature_idx = -1
                    else:
                        feature_idx = -1
                    
                    # è·å–ç‰¹å¾åç§°
                    if 0 <= feature_idx < len(feature_names):
                        feature_name = feature_names[feature_idx]
                    else:
                        feature_name = f"Feature_{feature_str}"
                    
                    # åˆ¤æ–­å½“å‰èŠ‚ç‚¹æ˜¯å·¦å­èŠ‚ç‚¹è¿˜æ˜¯å³å­èŠ‚ç‚¹
                    if pd.notna(left_child) and current_node_id == left_child:
                        operator = "<="
                    elif pd.notna(right_child) and current_node_id == right_child:
                        operator = ">"
                    else:
                        # æ— æ³•ç¡®å®šï¼Œè·³è¿‡
                        current_node_id = parent_id_str
                        continue
                    
                    # æ ¼å¼åŒ–è§„åˆ™
                    if category_prefixes and any(feature_name.startswith(prefix) for prefix in category_prefixes):
                        # ç±»åˆ«ç‰¹å¾
                        rule = f"{feature_name} æ˜¯ {int(threshold)} ç±»"
                    else:
                        # è¿ç»­ç‰¹å¾
                        rule = f"{feature_name} {operator} {threshold:.4f}"
                    
                    path.append(rule)
                
                # ç§»åŠ¨åˆ°çˆ¶èŠ‚ç‚¹
                current_node_id = parent_id_str
            
            # åè½¬è·¯å¾„ï¼Œä»æ ¹åˆ°å¶å­
            path.reverse()
            return path if path else None
            
        except Exception as e:
            import traceback
            logger.warning(f"è§£æå¶å­è·¯å¾„å¤±è´¥: {e}")
            traceback.print_exc()
            return None

    def save_models(self, gbdt_model, lr_model, category_features, continuous_features):
        """
        ä¿å­˜æ¨¡å‹å’Œé…ç½®
        """
        os.makedirs(self.output_dir, exist_ok=True)

        # ä¿å­˜ GBDT æ¨¡å‹
        gbdt_model_path = os.path.join(self.output_dir, 'gbdt_model.txt')
        gbdt_model.booster_.save_model(gbdt_model_path)
        logger.info(f"GBDT æ¨¡å‹å·²ä¿å­˜è‡³ {gbdt_model_path}")

        # ä¿å­˜ LR æ¨¡å‹
        import pickle
        lr_model_path = os.path.join(self.output_dir, 'lr_model.pkl')
        with open(lr_model_path, 'wb') as f:
            pickle.dump(lr_model, f)
        logger.info(f"LR æ¨¡å‹å·²ä¿å­˜è‡³ {lr_model_path}")

        # ä¿å­˜å®é™…è®­ç»ƒçš„æ ‘æ•°é‡
        actual_n_estimators = gbdt_model.best_iteration_
        with open(os.path.join(self.output_dir, 'actual_n_estimators.csv'), 'w') as f:
            f.write(f"actual_n_estimators,{actual_n_estimators}\n")
        logger.info(f"å®é™…æ ‘æ•°é‡å·²ä¿å­˜è‡³ {self.output_dir}/actual_n_estimators.csv")

        # ä¿å­˜ç‰¹å¾é…ç½®
        with open(os.path.join(self.output_dir, 'category_features.csv'), 'w') as f:
            f.write(','.join(category_features))
        logger.info(f"ç±»åˆ«ç‰¹å¾å·²ä¿å­˜è‡³ {self.output_dir}/category_features.csv")

        with open(os.path.join(self.output_dir, 'continuous_features.csv'), 'w') as f:
            f.write(','.join(continuous_features))
        logger.info(f"è¿ç»­ç‰¹å¾å·²ä¿å­˜è‡³ {self.output_dir}/continuous_features.csv")

    def show_model_interpretation_prompt(self):
        """
        æ˜¾ç¤ºæ¨¡å‹è§£è¯»æç¤º
        """
        print("\n" + "="*70)
        logger.info("æ¨¡å‹å¯è§£é‡Šæ€§åˆ†ææç¤º")
        print("="*70)
        print("è®­ç»ƒå®Œæˆåï¼Œå°†ç”Ÿæˆä»¥ä¸‹å¯è§£é‡Šæ€§æŠ¥å‘Šï¼š")
        print("1. gbdt_feature_importance.csv - GBDT ç‰¹å¾é‡è¦æ€§ï¼ˆå«å½±å“æ–¹å‘ï¼‰")
        print("2. lr_leaf_coefficients.csv - LR æ¨¡å‹çš„å¶å­èŠ‚ç‚¹ç³»æ•°")
        print("3. roc_curve.png - ROC æ›²çº¿å›¾")
        print("4. å¶å­è§„åˆ™è§£æ - é«˜æƒé‡å¶å­èŠ‚ç‚¹çš„å†³ç­–è·¯å¾„")
        print("\nğŸ’¡ ä½¿ç”¨å»ºè®®ï¼š")
        print("- å…³æ³¨ Gain é‡è¦æ€§é«˜çš„ç‰¹å¾ï¼Œå®ƒä»¬å¯¹æ¨¡å‹è´¡çŒ®æœ€å¤§")
        print("- æ­£å‘å½±å“ï¼ˆPositiveï¼‰è¡¨ç¤ºç‰¹å¾å€¼è¶Šå¤§ï¼Œé¢„æµ‹ä¸ºæ­£ç±»çš„æ¦‚ç‡è¶Šé«˜")
        print("- è´Ÿå‘å½±å“ï¼ˆNegativeï¼‰è¡¨ç¤ºç‰¹å¾å€¼è¶Šå¤§ï¼Œé¢„æµ‹ä¸ºæ­£ç±»çš„æ¦‚ç‡è¶Šä½")
        print("- LR ç³»æ•°ç»å¯¹å€¼å¤§çš„å¶å­èŠ‚ç‚¹è¡¨ç¤ºé‡è¦çš„å†³ç­–è§„åˆ™")
        print("="*70 + "\n")
