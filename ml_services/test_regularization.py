"""
æ­£åˆ™åŒ–ç­–ç•¥éªŒè¯è„šæœ¬ï¼ˆç®€åŒ–ç‰ˆï¼‰
ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®æµ‹è¯•ä¸åŒL1/L2é…ç½®å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“

ç›®æ ‡ï¼š
- éªŒè¯å½“å‰æ­£åˆ™åŒ–ç­–ç•¥ï¼ˆ0.15ï¼‰æ˜¯å¦æœ€ä¼˜
- æ‰¾åˆ°å¹³è¡¡æ‹Ÿåˆèƒ½åŠ›å’Œæ³›åŒ–èƒ½åŠ›çš„æœ€ä½³é…ç½®
- é™ä½ä¸€ä¸ªæœˆæ¨¡å‹çš„æ³¢åŠ¨æ€§

æ³¨æ„ï¼šæ­¤è„šæœ¬ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®è¿›è¡Œæ¦‚å¿µéªŒè¯
å®é™…åº”ç”¨æ—¶åº”ä½¿ç”¨çœŸå®æ•°æ®
"""

import pandas as pd
import numpy as np
from lightgbm import LGBMClassifier
from sklearn.metrics import accuracy_score, log_loss
from datetime import datetime
import os


# æµ‹è¯•é…ç½®
TEST_CONFIGS = [
    {'reg_alpha': 0.1, 'reg_lambda': 0.1, 'name': 'baseline'},
    {'reg_alpha': 0.12, 'reg_lambda': 0.12, 'name': 'light'},
    {'reg_alpha': 0.15, 'reg_lambda': 0.15, 'name': 'current'},
    {'reg_alpha': 0.18, 'reg_lambda': 0.18, 'name': 'strong'},
    {'reg_alpha': 0.2, 'reg_lambda': 0.2, 'name': 'very_strong'},
]

# åŸºç¡€æ¨¡å‹å‚æ•°ï¼ˆä¸€ä¸ªæœˆæ¨¡å‹ï¼‰
BASE_PARAMS = {
    'n_estimators': 45,
    'learning_rate': 0.025,
    'max_depth': 4,
    'num_leaves': 13,
    'min_child_samples': 35,
    'subsample': 0.65,
    'colsample_bytree': 0.65,
    'min_split_gain': 0.12,
    'feature_fraction': 0.65,
    'bagging_fraction': 0.65,
    'bagging_freq': 5,
    'random_state': 42,
    'verbose': -1
}


def generate_synthetic_data(n_samples=1000, n_features=10, noise_level=0.1):
    """
    ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®ç”¨äºæµ‹è¯•
    
    Args:
        n_samples: æ ·æœ¬æ•°é‡
        n_features: ç‰¹å¾æ•°é‡
        noise_level: å™ªå£°æ°´å¹³
    
    Returns:
        X, y: ç‰¹å¾å’Œæ ‡ç­¾
    """
    np.random.seed(42)
    
    # ç”Ÿæˆç‰¹å¾
    X = np.random.randn(n_samples, n_features)
    
    # ç”Ÿæˆç›®æ ‡å˜é‡ï¼ˆå¸¦æœ‰ä¸€å®šçš„ä¿¡å·ï¼‰
    # å‰5ä¸ªç‰¹å¾å¯¹ç›®æ ‡æœ‰å½±å“
    signal = X[:, :5].sum(axis=1) * 0.3
    noise = np.random.randn(n_samples) * noise_level
    y_proba = 1 / (1 + np.exp(-(signal + noise)))
    
    # è½¬æ¢ä¸ºäºŒåˆ†ç±»æ ‡ç­¾
    y = (y_proba > 0.5).astype(int)
    
    # æ·»åŠ ç‰¹å¾åç§°
    feature_names = [f'feature_{i}' for i in range(n_features)]
    X_df = pd.DataFrame(X, columns=feature_names)
    
    return X_df, pd.Series(y)


def time_series_cross_validation(X, y, n_splits=5):
    """
    æ—¶é—´åºåˆ—äº¤å‰éªŒè¯
    
    Args:
        X: ç‰¹å¾æ•°æ®
        y: æ ‡ç­¾æ•°æ®
        n_splits: åˆ†å‰²æ•°é‡
    
    Returns:
        generator: ç”Ÿæˆå™¨ï¼Œæ¯æ¬¡è¿”å›ä¸€ä¸ªfoldçš„æ•°æ®
    """
    n_samples = len(X)
    fold_size = n_samples // (n_splits + 1)
    
    for i in range(n_splits):
        # æ—¶é—´åºåˆ—åˆ†å‰²ï¼šå‰i+1ä¸ªfoldä½œä¸ºè®­ç»ƒï¼Œç¬¬i+2ä¸ªfoldä½œä¸ºéªŒè¯
        train_end = fold_size * (i + 1)
        val_start = train_end
        val_end = train_end + fold_size
        
        X_train = X.iloc[:train_end]
        y_train = y.iloc[:train_end]
        X_val = X.iloc[val_start:val_end]
        y_val = y.iloc[val_start:val_end]
        
        if len(X_train) == 0 or len(X_val) == 0:
            continue
        
        yield X_train, y_train, X_val, y_val, i + 1


def test_regularization_config(X, y, config):
    """
    æµ‹è¯•å•ä¸ªæ­£åˆ™åŒ–é…ç½®
    
    Args:
        X: ç‰¹å¾æ•°æ®
        y: æ ‡ç­¾æ•°æ®
        config: é…ç½®å­—å…¸
    
    Returns:
        dict: æµ‹è¯•ç»“æœ
    """
    print(f"\n{'='*60}")
    print(f"æµ‹è¯•é…ç½®: {config['name']}")
    print(f"reg_alpha={config['reg_alpha']}, reg_lambda={config['reg_lambda']}")
    print(f"{'='*60}")
    
    # åˆå¹¶å‚æ•°
    params = BASE_PARAMS.copy()
    params['reg_alpha'] = config['reg_alpha']
    params['reg_lambda'] = config['reg_lambda']
    
    # è¿è¡Œ5æŠ˜äº¤å‰éªŒè¯
    fold_scores = []
    fold_losses = []
    
    for X_train, y_train, X_val, y_val, fold_num in time_series_cross_validation(X, y):
        # è®­ç»ƒæ¨¡å‹
        model = LGBMClassifier(**params)
        model.fit(X_train, y_train)
        
        # é¢„æµ‹
        y_pred = model.predict(X_val)
        y_pred_proba = model.predict_proba(X_val)[:, 1]
        
        # è®¡ç®—æŒ‡æ ‡
        accuracy = accuracy_score(y_val, y_pred)
        loss = log_loss(y_val, y_pred_proba)
        
        fold_scores.append(accuracy)
        fold_losses.append(loss)
        
        print(f"  Fold {fold_num}: å‡†ç¡®ç‡={accuracy:.4f}, LogLoss={loss:.4f}")
    
    # è®¡ç®—æ±‡æ€»æŒ‡æ ‡
    avg_accuracy = np.mean(fold_scores)
    std_accuracy = np.std(fold_scores)
    avg_loss = np.mean(fold_losses)
    std_loss = np.std(fold_losses)
    
    # è®¡ç®—ç¨³å®šæ€§è¯„åˆ†ï¼ˆ1 - æ ‡å‡†å·®/å¹³å‡å€¼ï¼‰
    stability_score = 1 - (std_accuracy / avg_accuracy) if avg_accuracy > 0 else 0
    
    # æ‰¾å‡ºæœ€å¥½å’Œæœ€å·®çš„fold
    best_fold = max(fold_scores)
    worst_fold = min(fold_scores)
    fold_range = best_fold - worst_fold
    
    print(f"\n  å¹³å‡å‡†ç¡®ç‡: {avg_accuracy:.4f} (+/- {std_accuracy:.4f})")
    print(f"  å¹³å‡LogLoss: {avg_loss:.4f} (+/- {std_loss:.4f})")
    print(f"  ç¨³å®šæ€§è¯„åˆ†: {stability_score:.4f} (è¶Šé«˜è¶Šå¥½)")
    print(f"  æœ€ä½³Fold: {best_fold:.4f}")
    print(f"  æœ€å·®Fold: {worst_fold:.4f}")
    print(f"  FoldèŒƒå›´: {fold_range:.4f} (è¶Šå°è¶Šå¥½)")
    
    result = {
        'config': config['name'],
        'reg_alpha': config['reg_alpha'],
        'reg_lambda': config['reg_lambda'],
        'avg_accuracy': avg_accuracy,
        'std_accuracy': std_accuracy,
        'avg_loss': avg_loss,
        'std_loss': std_loss,
        'stability_score': stability_score,
        'best_fold': best_fold,
        'worst_fold': worst_fold,
        'fold_range': fold_range,
        'fold_scores': fold_scores,
        'fold_losses': fold_losses
    }
    
    return result


def compare_results(results):
    """
    å¯¹æ¯”æµ‹è¯•ç»“æœ
    
    Args:
        results: æµ‹è¯•ç»“æœåˆ—è¡¨
    
    Returns:
        DataFrame: ç»“æœå¯¹æ¯”è¡¨
    """
    df = pd.DataFrame(results)
    
    # æ’åºï¼šä¼˜å…ˆå‡†ç¡®ç‡ï¼Œå…¶æ¬¡ç¨³å®šæ€§
    df = df.sort_values(['avg_accuracy', 'stability_score'], ascending=[False, False])
    
    # æ·»åŠ æ’å
    df['rank_accuracy'] = df['avg_accuracy'].rank(ascending=False)
    df['rank_stability'] = df['stability_score'].rank(ascending=False)
    df['rank_combined'] = (df['rank_accuracy'] + df['rank_stability']) / 2
    
    return df


def generate_report(results, df_comparison):
    """
    ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
    
    Args:
        results: æµ‹è¯•ç»“æœåˆ—è¡¨
        df_comparison: å¯¹æ¯”DataFrame
    
    Returns:
        str: æŠ¥å‘Šæ–‡æœ¬
    """
    report = f"""
# æ­£åˆ™åŒ–ç­–ç•¥éªŒè¯æŠ¥å‘Š
ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## æµ‹è¯•é…ç½®
"""
    for config in TEST_CONFIGS:
        report += f"- {config['name']}: reg_alpha={config['reg_alpha']}, reg_lambda={config['reg_lambda']}\n"
    
    report += f"""
## ç»“æœå¯¹æ¯”

| é…ç½® | reg_alpha | reg_lambda | å¹³å‡å‡†ç¡®ç‡ | æ ‡å‡†å·® | ç¨³å®šæ€§è¯„åˆ† | LogLoss | FoldèŒƒå›´ |
|------|-----------|------------|-----------|--------|-----------|---------|---------|
"""
    
    for _, row in df_comparison.iterrows():
        report += f"| {row['config']} | {row['reg_alpha']} | {row['reg_lambda']} | {row['avg_accuracy']:.4f} | {row['std_accuracy']:.4f} | {row['stability_score']:.4f} | {row['avg_loss']:.4f} | {row['fold_range']:.4f} |\n"
    
    report += f"""
## æ¨èé…ç½®

### æœ€é«˜å‡†ç¡®ç‡é…ç½®
"""
    best_accuracy = df_comparison.iloc[0]
    report += f"- **{best_accuracy['config']}**: å¹³å‡å‡†ç¡®ç‡={best_accuracy['avg_accuracy']:.4f}, æ ‡å‡†å·®={best_accuracy['std_accuracy']:.4f}\n"
    
    report += f"""
### æœ€ç¨³å®šé…ç½®
"""
    most_stable = df_comparison.sort_values('stability_score', ascending=False).iloc[0]
    report += f"- **{most_stable['config']}**: ç¨³å®šæ€§è¯„åˆ†={most_stable['stability_score']:.4f}, å¹³å‡å‡†ç¡®ç‡={most_stable['avg_accuracy']:.4f}\n"
    
    report += f"""
### ç»¼åˆæ¨è
"""
    best_combined = df_comparison.sort_values('rank_combined').iloc[0]
    report += f"- **{best_combined['config']}**: ç»¼åˆæ’å={best_combined['rank_combined']:.1f}\n"
    report += f"  - å¹³å‡å‡†ç¡®ç‡: {best_combined['avg_accuracy']:.4f}\n"
    report += f"  - ç¨³å®šæ€§è¯„åˆ†: {best_combined['stability_score']:.4f}\n"
    report += f"  - FoldèŒƒå›´: {best_combined['fold_range']:.4f}\n"
    
    report += f"""
## å…³é”®å‘ç°

1. **å½“å‰é…ç½®ï¼ˆcurrentï¼‰è¡¨ç°**:
   - å¹³å‡å‡†ç¡®ç‡: {df_comparison[df_comparison['config']=='current']['avg_accuracy'].values[0]:.4f}
   - ç¨³å®šæ€§è¯„åˆ†: {df_comparison[df_comparison['config']=='current']['stability_score'].values[0]:.4f}
   - FoldèŒƒå›´: {df_comparison[df_comparison['config']=='current']['fold_range'].values[0]:.4f}

2. **ä¸baselineå¯¹æ¯”**:
   - å‡†ç¡®ç‡å˜åŒ–: {df_comparison[df_comparison['config']=='current']['avg_accuracy'].values[0] - df_comparison[df_comparison['config']=='baseline']['avg_accuracy'].values[0]:+.4f}
   - ç¨³å®šæ€§å˜åŒ–: {df_comparison[df_comparison['config']=='current']['stability_score'].values[0] - df_comparison[df_comparison['config']=='baseline']['stability_score'].values[0]:+.4f}

3. **æœ€ä¼˜é…ç½®å»ºè®®**:
   - å¦‚æœä¼˜å…ˆå‡†ç¡®ç‡: ä½¿ç”¨ {best_accuracy['config']} (reg_alpha={best_accuracy['reg_alpha']})
   - å¦‚æœä¼˜å…ˆç¨³å®šæ€§: ä½¿ç”¨ {most_stable['config']} (reg_alpha={most_stable['reg_alpha']})
   - å¦‚æœå¹³è¡¡ä¸¤è€…: ä½¿ç”¨ {best_combined['config']} (reg_alpha={best_combined['reg_alpha']})

## é‡è¦è¯´æ˜

âš ï¸  **æ³¨æ„**: æ­¤æµ‹è¯•ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®è¿›è¡Œæ¦‚å¿µéªŒè¯

- **æ•°æ®æ¥æº**: æ¨¡æ‹Ÿæ•°æ®ï¼ˆ1000ä¸ªæ ·æœ¬ï¼Œ10ä¸ªç‰¹å¾ï¼‰
- **ä¿¡å·å¼ºåº¦**: ä¸­ç­‰ï¼ˆå‰5ä¸ªç‰¹å¾å¯¹ç›®æ ‡æœ‰å½±å“ï¼‰
- **å™ªå£°æ°´å¹³**: 0.1
- **å®é™…åº”ç”¨**: éœ€è¦ä½¿ç”¨çœŸå®æ¸¯è‚¡æ•°æ®é‡æ–°éªŒè¯

### æ¨¡æ‹Ÿæ•°æ® vs çœŸå®æ•°æ®

| æŒ‡æ ‡ | æ¨¡æ‹Ÿæ•°æ® | çœŸå®æ•°æ® |
|------|---------|---------|
| æ ·æœ¬æ•°é‡ | 1000 | ~50000+ |
| ç‰¹å¾æ•°é‡ | 10 | 2936 |
| ä¿¡å·å¼ºåº¦ | ä¸­ç­‰ | æœªçŸ¥ |
| å™ªå£°æ°´å¹³ | 0.1 | æœªçŸ¥ |
| å¸‚åœºå¤æ‚æ€§ | ç®€å• | å¤æ‚ |

### å»ºè®®çš„éªŒè¯æ­¥éª¤

1. **åœ¨çœŸå®æ•°æ®ä¸ŠéªŒè¯**:
   ```bash
   # ä½¿ç”¨å®Œæ•´æ•°æ®é‡æ–°è®­ç»ƒï¼Œæµ‹è¯•ä¸åŒæ­£åˆ™åŒ–é…ç½®
   python ml_services/ml_trading_model.py --mode train --horizon 20 --model-type lgbm
   ```

2. **å¯¹æ¯”å®é™…æ€§èƒ½**:
   - è®°å½•5æŠ˜äº¤å‰éªŒè¯çš„å‡†ç¡®ç‡å’Œæ ‡å‡†å·®
   - å¯¹æ¯”ä¸åŒé…ç½®çš„å®é™…è¡¨ç°
   - é€‰æ‹©åœ¨å®é™…æ•°æ®ä¸Šè¡¨ç°æœ€å¥½çš„é…ç½®

3. **ç›‘æ§ç¨³å®šæ€§**:
   - è§‚å¯Ÿå„Foldä¹‹é—´çš„å·®å¼‚
   - ä¼˜å…ˆé€‰æ‹©FoldèŒƒå›´è¾ƒå°çš„é…ç½®
   - ç¡®ä¿æ¨¡å‹åœ¨ä¸åŒæ—¶æœŸéƒ½èƒ½ç¨³å®šè¡¨ç°

## ä¸‹ä¸€æ­¥è¡ŒåŠ¨

### ç«‹å³è¡ŒåŠ¨
1. æ ¹æ®æœ¬æµ‹è¯•ç»“æœï¼Œé€‰æ‹©æ¨èçš„é…ç½®
2. ä¿®æ”¹ `ml_services/ml_trading_model.py` ä¸­çš„å‚æ•°
3. é‡æ–°è®­ç»ƒä¸€ä¸ªæœˆæ¨¡å‹

### åç»­éªŒè¯
1. ä½¿ç”¨çœŸå®æ•°æ®é‡æ–°éªŒè¯æ­£åˆ™åŒ–ç­–ç•¥
2. ç›‘æ§æ¨¡å‹åœ¨å®é™…å¸‚åœºä¸­çš„è¡¨ç°
3. æ ¹æ®å®é™…è¡¨ç°è¿›ä¸€æ­¥è°ƒæ•´å‚æ•°

### é•¿æœŸä¼˜åŒ–
1. å®šæœŸé‡æ–°è¯„ä¼°æ­£åˆ™åŒ–ç­–ç•¥
2. æ ¹æ®å¸‚åœºå˜åŒ–è°ƒæ•´å‚æ•°
3. å»ºç«‹è‡ªåŠ¨åŒ–çš„å‚æ•°è°ƒä¼˜æµç¨‹

"""
    
    return report


def main():
    """ä¸»å‡½æ•°"""
    print("="*60)
    print("ğŸš€ æ­£åˆ™åŒ–ç­–ç•¥éªŒè¯ï¼ˆæ¨¡æ‹Ÿæ•°æ®ï¼‰")
    print("="*60)
    print("\nâš ï¸  æ³¨æ„: æ­¤æµ‹è¯•ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®è¿›è¡Œæ¦‚å¿µéªŒè¯")
    print("    å®é™…åº”ç”¨æ—¶éœ€è¦ä½¿ç”¨çœŸå®æ¸¯è‚¡æ•°æ®\n")
    
    # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
    print("ğŸ“Š ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®...")
    X, y = generate_synthetic_data(n_samples=1000, n_features=10, noise_level=0.1)
    print(f"  âœ… ç”Ÿæˆæ•°æ®: {len(X)} ä¸ªæ ·æœ¬, {len(X.columns)} ä¸ªç‰¹å¾")
    
    # æµ‹è¯•æ‰€æœ‰é…ç½®
    results = []
    for config in TEST_CONFIGS:
        result = test_regularization_config(X, y, config)
        results.append(result)
    
    # å¯¹æ¯”ç»“æœ
    df_comparison = compare_results(results)
    
    # ä¿å­˜ç»“æœ
    output_dir = 'output'
    os.makedirs(output_dir, exist_ok=True)
    
    # ä¿å­˜CSV
    csv_path = os.path.join(output_dir, 'regularization_test_results.csv')
    df_comparison.to_csv(csv_path, index=False)
    print(f"\nâœ… ç»“æœå·²ä¿å­˜åˆ° {csv_path}")
    
    # ç”ŸæˆæŠ¥å‘Š
    report = generate_report(results, df_comparison)
    
    # ä¿å­˜æŠ¥å‘Š
    report_path = os.path.join(output_dir, 'regularization_test_report.md')
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(report)
    print(f"âœ… æŠ¥å‘Šå·²ä¿å­˜åˆ° {report_path}")
    
    # æ‰“å°æ±‡æ€»
    print("\n" + "="*60)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»")
    print("="*60)
    print(df_comparison[['config', 'reg_alpha', 'reg_lambda', 'avg_accuracy', 'std_accuracy', 'stability_score', 'fold_range']].to_string(index=False))
    
    print("\n" + "="*60)
    print("âœ… æµ‹è¯•å®Œæˆï¼")
    print("="*60)
    print("\nğŸ“– æŸ¥çœ‹å®Œæ•´æŠ¥å‘Š: output/regularization_test_report.md")


if __name__ == '__main__':
    main()