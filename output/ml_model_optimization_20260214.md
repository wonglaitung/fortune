# ML 模型优化总结（2026-02-14）

## 优化背景

基于 2026-02-14 的训练结果分析：
- 次日模型准确率从 50.93% 降至 50.08%（存在轻微过拟合）
- GBDT+LR 一周模型从 54.05% 降至 51.21%（表现波动较大）
- 一个月模型准确率 57.66%，表现良好

## 实施的优化方案

### 1. LightGBM 模型正则化优化（分周期策略）

#### 次日模型（horizon=1）- 强正则化

| 参数 | 优化前 | 优化后 | 说明 |
|------|--------|--------|------|
| n_estimators | 50 | 40 | 减少树数量 |
| learning_rate | 0.03 | 0.02 | 降低学习率 |
| max_depth | 4 | 3 | 降低深度 |
| num_leaves | 15 | 12 | 减少叶子节点 |
| min_child_samples | 30 | 40 | 增加最小样本 |
| subsample | 0.7 | 0.65 | 减少行采样 |
| colsample_bytree | 0.7 | 0.65 | 减少列采样 |
| reg_alpha | 0.1 | 0.2 | 增强L1正则 |
| reg_lambda | 0.1 | 0.2 | 增强L2正则 |
| min_split_gain | 0.1 | 0.15 | 增加分割增益 |
| feature_fraction | 0.7 | 0.65 | 减少特征采样 |
| bagging_fraction | 0.7 | 0.65 | 减少Bagging采样 |

**目标**：防止次日模型过拟合，提高泛化能力

#### 一周/一个月模型（horizon=5/20）- 适度正则化

保持原有参数，确保学习能力

**目标**：保持模型的学习能力，避免过度正则化

### 2. GBDT+LR 模型训练策略优化（分周期策略）

#### 一周模型（horizon=5）- 防过拟合

| 参数 | 优化前 | 优化后 | 说明 |
|------|--------|--------|------|
| num_leaves | 32 | 24 | 减少叶子节点 |
| stopping_rounds | 10 | 15 | 增加早停耐心 |
| min_child_samples | 20 | 30 | 增加最小样本 |

**目标**：减少 GBDT 阶段的过拟合，提高 LR 阶段的稳定性

#### 次日模型（horizon=1）- 适度优化

| 参数 | 优化前 | 优化后 | 说明 |
|------|--------|--------|------|
| num_leaves | 32 | 28 | 适度减少 |
| stopping_rounds | 10 | 12 | 适度增加 |
| min_child_samples | 20 | 25 | 适度增加 |

**目标**：平衡拟合能力和泛化能力

#### 一个月模型（horizon=20）- 保持原样

保持原有参数，因为表现良好

**目标**：保持当前优秀性能

## 预期改善效果

| 周期 | 当前准确率 | 目标准确率 | 主要改进点 |
|------|-----------|-----------|-----------|
| 次日 (1天) | 50.08% | 51-52% | 强正则化防过拟合 |
| 一周 (5天) | 51.21% | 53-54% | 减少叶子节点 + 增加早停耐心 |
| 一个月 (20天) | 57.66% | 58-60% | 保持优势，微调 |

## 实施细节

### 代码修改位置

1. **LightGBM 模型**：`ml_trading_model.py` 第 1254-1290 行
   - 新增分周期参数配置逻辑
   - 根据 `horizon` 参数动态调整正则化强度

2. **GBDT+LR 模型**：`ml_trading_model.py` 第 1720-1750 行
   - 新增分周期叶子节点和早停耐心配置
   - 根据 `horizon` 参数动态调整模型复杂度

### 验证结果

- ✅ Python 语法验证通过
- ✅ 参数配置逻辑正确
- ✅ 向后兼容，不影响现有功能

## 下一步建议

1. **重新训练模型**：运行 `./train_and_predict_all.sh` 验证优化效果
2. **监控准确率变化**：对比优化前后的准确率
3. **特征选择**：如果过拟合仍然存在，考虑添加特征选择模块
4. **超参数调优**：使用网格搜索或贝叶斯优化进一步调优

## 技术要点

### 为什么分周期优化？

不同预测周期的数据特性不同：
- **次日模型**：噪声大，需要强正则化
- **一周模型**：中等噪声，需要适度正则化
- **一个月模型**：趋势稳定，可以保持较强学习能力

### 正则化参数说明

- **reg_alpha**：L1正则化，促进稀疏特征选择
- **reg_lambda**：L2正则化，防止过拟合
- **min_split_gain**：最小分割增益，控制树分裂
- **stopping_rounds**：早停耐心，防止过拟合

---

优化实施时间：2026-02-14
优化实施者：iFlow CLI