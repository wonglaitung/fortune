#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä½¿ç”¨ç‰¹å¾é€‰æ‹©ç»“æœè®­ç»ƒæ¨¡å‹

åŸºäºç‰¹å¾è¯„ä¼°ç»“æœï¼Œä½¿ç”¨ä¸åŒç‰¹å¾é›†è®­ç»ƒæ¨¡å‹å¹¶å¯¹æ¯”æ€§èƒ½
"""

import os
import sys
import argparse
from datetime import datetime
import warnings
import json
warnings.filterwarnings('ignore')

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import pandas as pd
from ml_services.ml_trading_model import MLTradingModel
from config import WATCHLIST
from ml_services.logger_config import get_logger

logger = get_logger('train_with_feature_selection')


def load_features_from_csv(csv_path, n_features=None, min_importance=None):
    """
    ä»ç‰¹å¾é‡è¦æ€§ CSV åŠ è½½ç‰¹å¾åˆ—è¡¨

    å‚æ•°:
    - csv_path: CSV æ–‡ä»¶è·¯å¾„
    - n_features: é€‰æ‹©å‰ N ä¸ªç‰¹å¾
    - min_importance: æœ€å°é‡è¦æ€§é˜ˆå€¼

    è¿”å›:
    - features: ç‰¹å¾åç§°åˆ—è¡¨
    """
    logger.info(f"åŠ è½½ç‰¹å¾åˆ—è¡¨: {csv_path}")

    df = pd.read_csv(csv_path)

    # åº”ç”¨è¿‡æ»¤æ¡ä»¶
    filtered_df = df.copy()

    if min_importance is not None:
        filtered_df = filtered_df[filtered_df['Mean_Importance'] >= min_importance]
        logger.info(f"  é‡è¦æ€§é˜ˆå€¼: {min_importance} -> {len(filtered_df)} ä¸ªç‰¹å¾")

    if n_features is not None:
        filtered_df = filtered_df.head(n_features)
        logger.info(f"  Top N: {n_features} -> {len(filtered_df)} ä¸ªç‰¹å¾")

    features = filtered_df['Feature'].tolist()
    logger.info(f"  æœ€ç»ˆé€‰æ‹©: {len(features)} ä¸ªç‰¹å¾")

    return features


def train_model_with_features(
    model_type='lightgbm',
    horizon=5,
    num_stocks=10,
    feature_set_name='all_features',
    features=None,
    output_dir='output/models_with_feature_selection'
):
    """
    ä½¿ç”¨æŒ‡å®šç‰¹å¾é›†è®­ç»ƒæ¨¡å‹

    å‚æ•°:
    - model_type: æ¨¡å‹ç±»å‹
    - horizon: é¢„æµ‹å‘¨æœŸ
    - num_stocks: è®­ç»ƒè‚¡ç¥¨æ•°é‡
    - feature_set_name: ç‰¹å¾é›†åç§°ï¼ˆç”¨äºæ ‡è¯†ï¼‰
    - features: ç‰¹å¾åˆ—è¡¨ï¼ˆNone è¡¨ç¤ºä½¿ç”¨å…¨éƒ¨ç‰¹å¾ï¼‰
    - output_dir: è¾“å‡ºç›®å½•

    è¿”å›:
    - result: è®­ç»ƒç»“æœå­—å…¸
    """
    os.makedirs(output_dir, exist_ok=True)

    logger.info("=" * 70)
    logger.info(f"è®­ç»ƒæ¨¡å‹: {model_type}, ç‰¹å¾é›†: {feature_set_name}")
    logger.info("=" * 70)

    # åˆ›å»ºæ¨¡å‹å®ä¾‹
    model = MLTradingModel()
    model.horizon = horizon

    # è®¾ç½®ç‰¹å¾é€‰æ‹©
    if features is not None:
        model.use_feature_selection = True
        model.selected_features = features
        logger.info(f"ä½¿ç”¨ç‰¹å¾é€‰æ‹©: {len(features)} ä¸ªç‰¹å¾")
    else:
        model.use_feature_selection = False
        logger.info("ä½¿ç”¨å…¨éƒ¨ç‰¹å¾")

    # è·å–è®­ç»ƒè‚¡ç¥¨
    codes = list(WATCHLIST.keys())[:num_stocks]
    logger.info(f"è®­ç»ƒè‚¡ç¥¨æ•°é‡: {len(codes)}")

    # è®­ç»ƒæ¨¡å‹
    try:
        start_time = datetime.now()
        logger.info(f"\nå¼€å§‹è®­ç»ƒ...")

        # è°ƒç”¨ train æ–¹æ³•
        model.train(codes, horizon=horizon, use_feature_selection=model.use_feature_selection)

        end_time = datetime.now()
        training_time = (end_time - start_time).total_seconds()

        # è·å–éªŒè¯å‡†ç¡®ç‡ï¼ˆä» model_accuracy.json è¯»å–ï¼‰
        validation_accuracy = None
        validation_std = None

        try:
            accuracy_file = 'data/model_accuracy.json'
            if os.path.exists(accuracy_file):
                with open(accuracy_file, 'r', encoding='utf-8') as f:
                    accuracy_data = json.load(f)

                # æ ¹æ®æ¨¡å‹ç±»å‹å’ŒhorizonæŸ¥æ‰¾å‡†ç¡®ç‡
                key = f'{model_type}_{horizon}d'
                if key in accuracy_data:
                    validation_accuracy = accuracy_data[key]['accuracy']
                    validation_std = accuracy_data[key]['std']
                    logger.info(f"ä» {accuracy_file} è¯»å–åˆ°å‡†ç¡®ç‡: {validation_accuracy:.4f}")
                else:
                    logger.warning(f"æœªæ‰¾åˆ° {key} çš„å‡†ç¡®ç‡æ•°æ®")
        except Exception as e:
            logger.warning(f"è¯»å–å‡†ç¡®ç‡æ–‡ä»¶å¤±è´¥: {e}")

        logger.info(f"\nè®­ç»ƒå®Œæˆï¼")
        logger.info(f"è®­ç»ƒæ—¶é—´: {training_time:.2f} ç§’")

        if validation_accuracy:
            logger.info(f"éªŒè¯å‡†ç¡®ç‡: {validation_accuracy:.4f} (+/- {validation_std:.4f})")

        # ä¿å­˜æ¨¡å‹
        model_filename = f"{model_type}_{feature_set_name}_h{horizon}.pkl"
        model_path = os.path.join(output_dir, model_filename)

        model.save_model(model_path)
        logger.info(f"æ¨¡å‹å·²ä¿å­˜: {model_path}")

        result = {
            'feature_set': feature_set_name,
            'num_features': len(features) if features else 'all',
            'validation_accuracy': validation_accuracy,
            'validation_std': validation_std,
            'training_time': training_time,
            'model_path': model_path,
            'timestamp': datetime.now().isoformat()
        }

        return result

    except Exception as e:
        logger.error(f"è®­ç»ƒå¤±è´¥: {e}")
        import traceback
        logger.debug(traceback.format_exc())

        return {
            'feature_set': feature_set_name,
            'num_features': len(features) if features else 'all',
            'validation_accuracy': None,
            'validation_std': None,
            'training_time': None,
            'error': str(e),
            'timestamp': datetime.now().isoformat()
        }


def compare_feature_sets(
    model_type='lightgbm',
    horizon=5,
    num_stocks=10,
    output_dir='output/models_with_feature_selection'
):
    """
    å¯¹æ¯”ä¸åŒç‰¹å¾é›†çš„æ¨¡å‹æ€§èƒ½

    å‚æ•°:
    - model_type: æ¨¡å‹ç±»å‹
    - horizon: é¢„æµ‹å‘¨æœŸ
    - num_stocks: è®­ç»ƒè‚¡ç¥¨æ•°é‡
    - output_dir: è¾“å‡ºç›®å½•

    è¿”å›:
    - comparison_df: å¯¹æ¯”ç»“æœ DataFrame
    """
    logger.info("=" * 70)
    logger.info("å¯¹æ¯”ä¸åŒç‰¹å¾é›†çš„æ€§èƒ½")
    logger.info("=" * 70)

    # åŠ è½½ç‰¹å¾é‡è¦æ€§
    feature_csv = 'output/feature_eval_v2/feature_importance.csv'

    if not os.path.exists(feature_csv):
        logger.error(f"ç‰¹å¾é‡è¦æ€§æ–‡ä»¶ä¸å­˜åœ¨: {feature_csv}")
        logger.info("è¯·å…ˆè¿è¡Œ: python scripts/feature_eval_v2.py")
        return None

    # å®šä¹‰ä¸åŒçš„ç‰¹å¾é›†
    feature_sets = [
        {
            'name': 'all_features',
            'description': 'å…¨éƒ¨ç‰¹å¾ï¼ˆ3972ä¸ªï¼‰',
            'features': None
        },
        {
            'name': 'top_50',
            'description': 'Top 50 ç‰¹å¾',
            'features': load_features_from_csv(feature_csv, n_features=50)
        },
        {
            'name': 'top_100',
            'description': 'Top 100 ç‰¹å¾',
            'features': load_features_from_csv(feature_csv, n_features=100)
        },
        {
            'name': 'top_200',
            'description': 'Top 200 ç‰¹å¾',
            'features': load_features_from_csv(feature_csv, n_features=200)
        },
    ]

    # å¯é€‰ï¼šé«˜é‡è¦æ€§ä¸”ç¨³å®šçš„ç‰¹å¾
    try:
        df = pd.read_csv(feature_csv)
        stable_high = df[
            (df['Mean_Importance'] > 5) &  # é«˜é‡è¦æ€§
            (df['CV_Importance'] < 0.6)     # é«˜ç¨³å®šæ€§
        ].head(100)
        feature_sets.append({
            'name': 'stable_high_100',
            'description': 'é«˜é‡è¦æ€§ä¸”ç¨³å®šçš„100ä¸ªç‰¹å¾',
            'features': stable_high['Feature'].tolist()
        })
    except Exception as e:
        logger.warning(f"åˆ›å»ºç¨³å®šç‰¹å¾é›†å¤±è´¥: {e}")

    # è®­ç»ƒæ‰€æœ‰æ¨¡å‹
    results = []

    for feature_set in feature_sets:
        logger.info(f"\n{'='*70}")
        logger.info(f"ç‰¹å¾é›†: {feature_set['name']} - {feature_set['description']}")
        logger.info(f"{'='*70}")

        result = train_model_with_features(
            model_type=model_type,
            horizon=horizon,
            num_stocks=num_stocks,
            feature_set_name=feature_set['name'],
            features=feature_set['features'],
            output_dir=output_dir
        )

        result['description'] = feature_set['description']
        results.append(result)

    # åˆ›å»ºå¯¹æ¯” DataFrame
    comparison_df = pd.DataFrame(results)

    # æ‰“å°å¯¹æ¯”ç»“æœ
    logger.info("\n" + "=" * 70)
    logger.info("æ€§èƒ½å¯¹æ¯”ç»“æœ")
    logger.info("=" * 70)

    comparison_df_display = comparison_df[['feature_set', 'description', 'num_features', 'validation_accuracy', 'validation_std', 'training_time']].copy()

    # æ ¼å¼åŒ–å‡†ç¡®ç‡å’Œæ ‡å‡†å·®
    comparison_df_display['accuracy_display'] = comparison_df_display.apply(
        lambda row: f"{row['validation_accuracy']:.4f} (+/- {row['validation_std']:.4f})"
        if row['validation_accuracy'] is not None else "N/A", axis=1
    )
    comparison_df_display = comparison_df_display.drop(['validation_accuracy', 'validation_std'], axis=1)
    comparison_df_display = comparison_df_display.rename(columns={'accuracy_display': 'validation_accuracy'})

    # è®¡ç®—ç›¸å¯¹äºå…¨éƒ¨ç‰¹å¾çš„æ€§èƒ½æå‡
    if len(comparison_df) > 0 and comparison_df.iloc[0]['feature_set'] == 'all_features':
        baseline_acc = comparison_df.iloc[0]['validation_accuracy']
        baseline_time = comparison_df.iloc[0]['training_time']

        if baseline_acc:
            comparison_df_display['accuracy_change'] = comparison_df['validation_accuracy'].apply(
                lambda x: f"{(x - baseline_acc)*100:+.2f}%" if x is not None else "N/A"
            )
        if baseline_time:
            comparison_df_display['time_improvement'] = comparison_df['training_time'].apply(
                lambda x: f"{(1 - x/baseline_time)*100:+.1f}%" if x is not None else "N/A"
            )

    logger.info(f"\n{comparison_df_display.to_string(index=False)}")

    # ä¿å­˜å¯¹æ¯”ç»“æœ
    comparison_path = os.path.join(output_dir, f'comparison_{model_type}_h{horizon}.csv')
    comparison_df.to_csv(comparison_path, index=False, encoding='utf-8')
    logger.info(f"\nå¯¹æ¯”ç»“æœå·²ä¿å­˜: {comparison_path}")

    # ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
    report_path = os.path.join(output_dir, f'comparison_report_{model_type}_h{horizon}.txt')
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write("=" * 80 + "\n")
        f.write("ç‰¹å¾é€‰æ‹©å¯¹æ¯”æŠ¥å‘Š\n")
        f.write("=" * 80 + "\n\n")
        f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"æ¨¡å‹ç±»å‹: {model_type}\n")
        f.write(f"é¢„æµ‹å‘¨æœŸ: {horizon} å¤©\n")
        f.write(f"è®­ç»ƒè‚¡ç¥¨æ•°: {num_stocks}\n\n")

        f.write("=" * 80 + "\n")
        f.write("è¯¦ç»†ç»“æœ\n")
        f.write("=" * 80 + "\n\n")

        for i, row in comparison_df.iterrows():
            f.write(f"{i+1}. {row['feature_set']}\n")
            f.write(f"   æè¿°: {row['description']}\n")
            f.write(f"   ç‰¹å¾æ•°é‡: {row['num_features']}\n")

            if row['validation_accuracy'] is not None:
                f.write(f"   éªŒè¯å‡†ç¡®ç‡: {row['validation_accuracy']:.4f} (+/- {row['validation_std']:.4f})\n")

            if row['training_time']:
                f.write(f"   è®­ç»ƒæ—¶é—´: {row['training_time']:.2f} ç§’\n")

            if 'error' in row:
                f.write(f"   é”™è¯¯: {row['error']}\n")

            f.write("\n")

        # åˆ†æå’Œæ¨è
        f.write("=" * 80 + "\n")
        f.write("åˆ†æå’Œæ¨è\n")
        f.write("=" * 80 + "\n\n")

        if len(comparison_df) > 0:
            # è¿‡æ»¤å‡ºæœ‰å‡†ç¡®ç‡æ•°æ®çš„æ¨¡å‹
            valid_models = comparison_df[comparison_df['validation_accuracy'].notna()]

            if len(valid_models) > 0:
                # æ‰¾å‡ºæœ€å¥½çš„æ¨¡å‹
                best_idx = valid_models['validation_accuracy'].idxmax()
                best_model = comparison_df.iloc[best_idx]

                f.write("ğŸ“Š æ€§èƒ½åˆ†æ:\n")
                f.write(f"   æœ€ä½³æ¨¡å‹: {best_model['feature_set']}\n")
                f.write(f"   å‡†ç¡®ç‡: {best_model['validation_accuracy']:.4f} (+/- {best_model['validation_std']:.4f})\n")
                f.write(f"   ç‰¹å¾æ•°é‡: {best_model['num_features']}\n")
                if best_model['training_time']:
                    f.write(f"   è®­ç»ƒæ—¶é—´: {best_model['training_time']:.2f} ç§’\n")

                # è®¡ç®—é€Ÿåº¦æå‡
                baseline = comparison_df[comparison_df['feature_set'] == 'all_features']
                if len(baseline) > 0 and baseline.iloc[0]['training_time']:
                    baseline_time = baseline.iloc[0]['training_time']
                    if best_model['training_time']:
                        speedup = baseline_time / best_model['training_time']
                        f.write(f"   é€Ÿåº¦æå‡: {speedup:.2f}x\n")

                f.write("\nğŸ’¡ æ¨èå»ºè®®:\n")
                if best_model['feature_set'] != 'all_features':
                    f.write(f"   1. ä½¿ç”¨ {best_model['feature_set']} ç‰¹å¾é›†\n")
                    f.write(f"   2. è¯¥ç‰¹å¾é›†åœ¨å‡†ç¡®ç‡å’Œé€Ÿåº¦ä¹‹é—´å–å¾—äº†æœ€ä½³å¹³è¡¡\n")
                else:
                    f.write(f"   1. ä½¿ç”¨å…¨éƒ¨ç‰¹å¾ï¼ˆä½†å¯ä»¥è€ƒè™‘å‡å°‘ç‰¹å¾ä»¥æå‡é€Ÿåº¦ï¼‰\n")

                f.write(f"   2. å¯ä»¥å°è¯•ä¸åŒçš„ç‰¹å¾æ•°é‡æ¥ä¼˜åŒ–æ€§èƒ½\n")
            else:
                f.write("âš ï¸ è­¦å‘Š: æ²¡æœ‰æœ‰æ•ˆçš„å‡†ç¡®ç‡æ•°æ®å¯ä¾›åˆ†æ\n")

    logger.info(f"è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {report_path}")

    return comparison_df


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='ä½¿ç”¨ç‰¹å¾é€‰æ‹©ç»“æœè®­ç»ƒæ¨¡å‹')
    parser.add_argument('--mode', type=str, default='compare',
                       choices=['compare', 'train', 'analyze'],
                       help='è¿è¡Œæ¨¡å¼: compare(å¯¹æ¯”), train(è®­ç»ƒå•ä¸ª), analyze(ä»…åˆ†æï¼‰')
    parser.add_argument('--model_type', type=str, default='lightgbm',
                       choices=['lightgbm', 'gbdt', 'catboost'],
                       help='æ¨¡å‹ç±»å‹')
    parser.add_argument('--horizon', type=int, default=5,
                       choices=[1, 5, 20],
                       help='é¢„æµ‹å‘¨æœŸ')
    parser.add_argument('--num_stocks', type=int, default=10,
                       help='è®­ç»ƒè‚¡ç¥¨æ•°é‡')
    parser.add_argument('--feature_set', type=str, default='top_100',
                       choices=['top_50', 'top_100', 'top_200', 'all_features', 'stable_high_100'],
                       help='ç‰¹å¾é›†åç§°ï¼ˆtrain æ¨¡å¼ï¼‰')
    parser.add_argument('--output_dir', type=str,
                       default='output/models_with_feature_selection',
                       help='è¾“å‡ºç›®å½•')

    args = parser.parse_args()

    logger.info("=" * 70)
    logger.info("ä½¿ç”¨ç‰¹å¾é€‰æ‹©ç»“æœè®­ç»ƒæ¨¡å‹")
    logger.info("=" * 70)
    logger.info(f"æ¨¡å¼: {args.mode}")
    logger.info(f"æ¨¡å‹ç±»å‹: {args.model_type}")
    logger.info(f"é¢„æµ‹å‘¨æœŸ: {args.horizon} å¤©")
    logger.info(f"è‚¡ç¥¨æ•°é‡: {args.num_stocks}")

    if args.mode == 'compare':
        # å¯¹æ¯”æ¨¡å¼ï¼šè®­ç»ƒå¹¶å¯¹æ¯”æ‰€æœ‰ç‰¹å¾é›†
        comparison_df = compare_feature_sets(
            model_type=args.model_type,
            horizon=args.horizon,
            num_stocks=args.num_stocks,
            output_dir=args.output_dir
        )

        if comparison_df is not None:
            logger.info("\nâœ… å¯¹æ¯”å®Œæˆï¼")
            logger.info(f"ç»“æœä¿å­˜åœ¨: {args.output_dir}")

    elif args.mode == 'train':
        # è®­ç»ƒæ¨¡å¼ï¼šè®­ç»ƒå•ä¸ªæ¨¡å‹
        logger.info(f"\nè®­ç»ƒå•ä¸ªæ¨¡å‹: {args.feature_set}")

        feature_csv = 'output/feature_eval_v2/feature_importance.csv'

        # æ ¹æ®ç‰¹å¾é›†åç§°åŠ è½½ç‰¹å¾
        if args.feature_set == 'all_features':
            features = None
        elif args.feature_set == 'stable_high_100':
            df = pd.read_csv(feature_csv)
            features = df[
                (df['Mean_Importance'] > 5) &
                (df['CV_Importance'] < 0.6)
            ].head(100)['Feature'].tolist()
        else:
            n_features = int(args.feature_set.replace('top_', ''))
            features = load_features_from_csv(feature_csv, n_features=n_features)

        result = train_model_with_features(
            model_type=args.model_type,
            horizon=args.horizon,
            num_stocks=args.num_stocks,
            feature_set_name=args.feature_set,
            features=features,
            output_dir=args.output_dir
        )

        if result.get('validation_accuracy'):
            logger.info(f"\nâœ… è®­ç»ƒæˆåŠŸï¼")
            logger.info(f"éªŒè¯å‡†ç¡®ç‡: {result['validation_accuracy']:.4f}")
            logger.info(f"æ¨¡å‹è·¯å¾„: {result['model_path']}")
        else:
            logger.error(f"\nâŒ è®­ç»ƒå¤±è´¥: {result.get('error', 'Unknown')}")

    elif args.mode == 'analyze':
        # åˆ†ææ¨¡å¼ï¼šä»…åˆ†æç‰¹å¾é€‰æ‹©ç»“æœ
        logger.info(f"\nåˆ†æç‰¹å¾é€‰æ‹©ç»“æœ")

        feature_csv = 'output/feature_eval_v2/feature_importance.csv'
        df = pd.read_csv(feature_csv)

        logger.info(f"\nç‰¹å¾æ€»æ•°: {len(df)}")
        logger.info(f"\nTop 10 ç‰¹å¾:")
        for i, row in df.head(10).iterrows():
            logger.info(f"  {i+1:2d}. {row['Feature']:<40} {row['Mean_Importance']:>8.2f} (CV={row['CV_Importance']:.4f})")

        logger.info(f"\nç‰¹å¾é‡è¦æ€§ç»Ÿè®¡:")
        logger.info(f"  å¹³å‡å€¼: {df['Mean_Importance'].mean():.2f}")
        logger.info(f"  ä¸­ä½æ•°: {df['Mean_Importance'].median():.2f}")
        logger.info(f"  æœ€å¤§å€¼: {df['Mean_Importance'].max():.2f}")

        logger.info(f"\nâœ… åˆ†æå®Œæˆï¼")

    logger.info("\n" + "=" * 70)
    logger.info("å®Œæˆï¼")
    logger.info("=" * 70)


if __name__ == '__main__':
    main()
